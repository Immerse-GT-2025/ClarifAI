# ClarifAI - Adaptive AR for Concerts

An immersive augmented reality experience that enhances live concerts by providing real-time lyrics, performer tracking, and accessibility features.

## Features

- **Multi-language Support**: Available in English, Spanish, and French
- **Accessibility Features**: 
  - Dyslexia-friendly mode with OpenDyslexic font
  - Customizable text size and contrast
- **Real-time Lyrics Display**: Synchronized lyrics with swipe controls
- **Performer Tracking**: Automatic zoom and focus on performers
- **Smooth Transitions**: Gesture-based navigation between screens

## Technical Stack

- Lens Studio SDK
- JavaScript/TypeScript
- Custom UI Components
- Gesture Recognition System

## Project Structure

```
clarif-ai/
├── src/
│   ├── main.js        # Main application logic
│   └── config.js      # Configuration and constants
├── assets/
│   ├── fonts/         # Regular and dyslexic fonts
│   └── images/        # UI assets and icons
└── docs/             # Documentation
```

## Getting Started

1. Clone the repository:
   ```bash
   git clone https://github.com/Immerse-GT-2025/ClarifAI.git
   ```

2. Open the project in Lens Studio

3. Build and run the project

## Development

- Follow the [Lens Studio guidelines](https://docs.snap.com/lens-studio/references/guides/lens-features/tracking/face/face-effects) for AR development
- Use the provided configuration in `config.js` for customization
- Test thoroughly with different languages and accessibility settings

## Contributing

1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push to the branch
5. Create a Pull Request

## License

This project is licensed under the MIT License - see the LICENSE file for details.

## Team

Immerse GT 2025 Team

## Acknowledgments

- Lens Studio for AR capabilities
- OpenDyslexic for accessibility font
- Contributors and testers
